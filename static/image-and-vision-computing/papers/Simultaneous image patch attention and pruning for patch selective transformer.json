{
    "url": "https://www.sciencedirect.com/science/article/pii/S0262885624003445",
    "title": "Simultaneous image patch attention and pruning for patch selective transformer",
    "abstract": "Vision transformer models provide superior performance compared to convolutional neural networks for various computer vision tasks but require increased computational overhead with large datasets. This paper proposes a patch selective vision transformer that effectively selects patches to reduce computational costs while simultaneously extracting global and local self-representative patch information to maintain performance. The inter-patch attention in the transformer encoder emphasizes meaningful features by capturing the inter-patch relationships of features, and dynamic patch pruning is applied to the attentive patches using a learnable soft threshold that measures the maximum multi-head importance scores. The proposed patch attention and pruning method provides constraints to exploit dominant feature maps in conjunction with self-attention, thus avoiding the propagation of noisy or irrelevant information. The proposed patch-selective transformer also helps to address computer vision problems such as scale, background clutter, and partial occlusion, resulting in a lightweight and general-purpose vision transformer suitable for mobile devices.",
    "citation_count": "0",
    "year": "2024/10/01",
    "authors": [
        {
            "name": "Sunpil Kim",
            "country": ""
        },
        {
            "name": "Gang-Joon Yoon",
            "country": ""
        },
        {
            "name": "Jinjoo Song",
            "country": ""
        },
        {
            "name": "Sang Min Yoon",
            "country": ""
        }
    ],
    "keywords": []
}