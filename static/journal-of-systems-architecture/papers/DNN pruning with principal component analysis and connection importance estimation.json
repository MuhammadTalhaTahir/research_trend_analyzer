{
    "url": "https://www.sciencedirect.com/science/article/pii/S1383762121002307",
    "title": "DNN pruning with principal component analysis and connection importance estimation",
    "abstract": "DNN pruning reduces memory footprint and computational work of DNN-based solutions to improve performance and energy-efficiency. An effective pruning scheme should be able to systematically remove connections and/or neurons that are unnecessary or redundant, reducing the DNN size without any loss in accuracy. In this paper we show that some of the most popular pruning schemes, such as the Near Zero Weights, require an extremely time-consuming iterative process that requires retraining the DNN many times to tune the pruning hyperparameters. Then, we propose a DNN pruning scheme based on Principal Component Analysis and relative importance of each neuron’s connection (PCA+DIRIE) that automatically finds the optimized DNN in one shot without requiring hand-tuning of multiple parameters. The experimental results show the effectiveness of our method on several benchmarks. Notably, on ImageNet, PCA+DIRIE can prune up to 60% of ResNet-50 with negligible impact on accuracy.",
    "citation_count": "0",
    "year": "2022/01/01",
    "authors": [
        {
            "name": "Marc Riera",
            "country": ""
        },
        {
            "name": "José María Arnau",
            "country": ""
        },
        {
            "name": "Antonio González",
            "country": ""
        }
    ],
    "keywords": []
}