{
    "url": "https://www.sciencedirect.com/science/article/pii/S1383762120301806",
    "title": "Distributed learning dynamics of Multi-Armed Bandits for edge intelligence",
    "abstract": "Multi-agent  decision making  is a fundamental problem in  edge intelligence . In this paper, we study this problem for  IoT  networks under the distributed Multi-Armed Bandits (MAB) model. Most of existing works for distributed MAB demand long-time stable networks connected by powerful devices and hence may not be suitable for mobile  IoT  networks with harsh  IoT  constraints. To meet the challenge of  resource constraints  in mobile  IoT  environment, we propose a lightweight and robust learning algorithm in a dynamic network allowing  topology changes . In our model, each agent is assumed to have only limited memory and communicate with each other asynchronously. Moreover, we assume that the bandwidth for exchanging information is limited and each agent can transmit  O ( log 2 K )  bits ( K  denotes the number of arms) per communication.  Rigorous analysis  shows that despite these harsh constraints, the best arm/option can be identified collaboratively by the agents and the algorithm converges efficiently. Extensive experiments illustrate that the proposed algorithm exhibits good efficiency and stability in mobile settings.",
    "citation_count": "15",
    "year": "2021/03/01",
    "authors": [
        {
            "name": "Shuzhen Chen",
            "country": ""
        },
        {
            "name": "Youming Tao",
            "country": ""
        },
        {
            "name": "Dongxiao Yu",
            "country": ""
        },
        {
            "name": "Feng Li",
            "country": ""
        },
        {
            "name": "Bei Gong",
            "country": ""
        }
    ],
    "keywords": []
}