{
    "url": "https://www.sciencedirect.com/science/article/pii/S138376212030196X",
    "title": "Privacy attacks against deep learning models and their countermeasures",
    "abstract": "Recently,  deep learning  is considered an important concept that is used in a lot of important applications, which require accurate models, such as  image classification , identification of audio,  intrusion detection , and face recognition. However, building a good  deep learning model  needs a huge amount of data that is not easily provided, especially in the applications that need  sensitive information . Accordingly, researchers propose multiple methodologies for sharing the model rather than sharing the dataset itself. Nevertheless, it has been proven that the shared models still could leak a lot of sensitive information about the private data. In this work, we introduce a survey about the attacks that could be launched against the shared models and the countermeasures that could be taken to preserve the privacy of the sensitive data that is used for the training process.",
    "citation_count": "20",
    "year": "2021/03/01",
    "authors": [
        {
            "name": "Ahmed Shafee",
            "country": ""
        },
        {
            "name": "Tasneem A. Awaad",
            "country": ""
        }
    ],
    "keywords": []
}