{
    "url": "https://www.sciencedirect.com/science/article/pii/S0262885624002361",
    "title": "Active domain adaptation for semantic segmentation via dynamically balancing domainness and uncertainty",
    "abstract": "Active  domain adaptation  aims to enhance model adaptation performance by annotating a limited number of informative unlabeled target data. Traditional active learning strategies for  semantic segmentation  often neglect the presence of domain shifts, resulting in suboptimal results in domain adaptation scenarios. In this paper, we present a novel active domain adaptation approach for semantic segmentation that maximizes  segmentation performance  under domain shifts with a limited number of queried target labels. To recognize the most valuable samples for labeling, we introduce a new acquisition strategy. This strategy leverages a target domainness map to identify the most informative samples for reducing the domain gap and employs region-aware prediction uncertainty to explore ambiguous samples. Meanwhile, to optimize the efficiency of the acquisition strategy, we dynamically adjust the balance between prediction uncertainty and target domainness over the selection rounds. To further bolster adaptation performance, a smooth loss function is employed for the target data, which promotes consistency in local predictions. Extensive experiments on two benchmarks, GTAV  →  Cityscapes and SYNTHIA  →  Cityscapes, demonstrate that our method surpasses existing active domain adaptation methods for semantic segmentation. Moreover, it achieves comparable results to supervised performance with only 5% annotations in the target domain, validating the effectiveness of our method.",
    "citation_count": "2",
    "year": "2024/08/01",
    "authors": [
        {
            "name": "Siqi Zhang",
            "country": ""
        },
        {
            "name": "Lu Zhang",
            "country": ""
        },
        {
            "name": "Zhiyong Liu",
            "country": ""
        }
    ],
    "keywords": []
}