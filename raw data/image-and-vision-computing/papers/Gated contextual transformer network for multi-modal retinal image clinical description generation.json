{
    "url": "https://www.sciencedirect.com/science/article/pii/S0262885624000490",
    "title": "Gated contextual transformer network for multi-modal retinal image clinical description generation",
    "abstract": "Generating semantically meaningful and coherent clinical description for the diagnosis of  retinal images  has been a challenging task for both  Computer Vision  and  Natural Language Processing  domains. This is mainly due to the fact that the clinical descriptions generated by the  language model  are completely dependent on the type of retinal image representations learned by the vision model. This work investigates and proposes a unified approach to integrate multi-modal retinal  image visual  representations with corresponding clinical keyword embeddings which can aid the  language model  to learn the clinical semantics and generate lengthy, coherent clinical descriptions accurately. Our proposed approach, named the Gated Contextual Transformer Network, comprises two attention-based encoders that learn semantically discriminative attention-based representations from  retinal images  and clinical keywords, along with a Transformer Network for clinical description generation. The first encoder leverages a pre-trained Convolutional  Neural Network  (VGG19) and a Gated Contextual Attention module to learn discriminative attention-based representations from the multi-modal retinal images. The second encoder incorporates an Embedding layer and an Attention module to learn attention-based clinical keyword embeddings. The Transformer network consists of a fusion encoder that attentively integrates retinal image visual features with clinical keyword embeddings and a decoder that is responsible for generating semantically meaningful and coherent clinical descriptions. Our experimental studies on the benchmark DeepEyeNet dataset demonstrate that the proposed approach successfully generates clinical descriptions from multi-modal retinal images, meeting the standards of ophthalmologists. To support our claim, we provide qualitative and  quantitative evaluations  of the proposed approach. This includes reporting BLUE, CIDEr, and ROUGE scores for the predicted descriptions, as well as employing Visual Explanation for Clinical Description Generation.",
    "citation_count": "2",
    "year": "2024/03/01",
    "authors": [
        {
            "name": "Nagur Shareef Shaik",
            "country": ""
        },
        {
            "name": "Teja Krishna Cherukuri",
            "country": ""
        }
    ],
    "keywords": []
}