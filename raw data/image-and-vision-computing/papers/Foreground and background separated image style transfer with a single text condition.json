{
    "url": "https://www.sciencedirect.com/science/article/pii/S0262885624000593",
    "title": "Foreground and background separated image style transfer with a single text condition",
    "abstract": "Traditional image-based style transfer requires additional reference style images, making it less user-friendly. Text-based methods are more convenient but suffer from issues like slow generation, unclear content, and poor quality. In this work, we propose a new style transfer method SA2-CS (means Semantic-Aware and Salient Attention CLIPStyler), which is based on the Comparative Language Image Pretraining (CLIP) model and a  salient object detection  network. Masks obtained from the salient object detection network are utilized to guide the style transfer process, and various strategies are employed to optimize according to different masks. Adequate experiments with diverse  content images  and style text descriptions were conducted, demonstrating our method's advantages: the network is easily trainable and converges rapidly; it achieves stable, superior generation results compared to other methods. Our approach addresses over-stylization issues in the foreground, enhances foreground-background contrast, and enables precise control over style transfer in various semantic regions.",
    "citation_count": "2",
    "year": "2024/03/01",
    "authors": [
        {
            "name": "Yue Yu",
            "country": ""
        },
        {
            "name": "Jianming Wang",
            "country": ""
        },
        {
            "name": "Nengli Li",
            "country": ""
        }
    ],
    "keywords": []
}