{
    "url": "https://link.springer.com/article/10.1007/s10044-008-0101-6",
    "title": "Classification of dissimilarity data with a new flexible Mahalanobis-like metric",
    "abstract": "Statistical pattern recognition traditionally relies on feature-based representation. For many applications, such vector representation is not available and we only possess proximity data (distance, dissimilarity, similarity, ranks, etc.). In this paper, we consider a particular point of view on discriminant analysis from dissimilarity data. Our approach is inspired by the Gaussian classifier and we defined decision rules to mimic the behavior of a linear or a quadratic classifier. The number of parameters is limited (two per class). Numerical experiments on artificial and real data show interesting behavior compared to Support Vector Machines and to kNN classifier: (a) lower or equivalent error rate, (b) equivalent CPU time, (c) more robustness with sparse dissimilarity data.",
    "citation_count": 24,
    "year": "2008/09",
    "authors": [
        {
            "name": "Manolova, Agata",
            "country": "Bulgaria"
        },
        {
            "name": "Guérin-Dugué, Anne",
            "country": "France"
        }
    ],
    "keywords": [
        "Pattern Recognition"
    ]
}